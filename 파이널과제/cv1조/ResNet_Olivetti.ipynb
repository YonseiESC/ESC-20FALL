{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1606702377968,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "V9HjUZnD6Ixz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1606702379093,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "dd_sd4og6Ig5"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"Characterizes a dataset for PyTorch\"\n",
    "    def __init__(self, filenames, labels, transform=None):\n",
    "        \"Initialization\"\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(self.filenames)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"Generates one sample of data\"\n",
    "        # Select sample\n",
    "        filename = self.filenames[index]\n",
    "        X = Image.open(filename)\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)     # transform\n",
    "\n",
    "        y = torch.LongTensor([self.labels[index]])\n",
    "        return X, y\n",
    "\n",
    "## ---------------------- end of Dataloaders ---------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1606702380314,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "MQ7lL1Vb6IPd"
   },
   "outputs": [],
   "source": [
    "def conv2D_output_size(img_size, padding, kernel_size, stride):\n",
    "    # compute output shape of conv2D\n",
    "    outshape = (np.floor((img_size[0] + 2 * padding[0] - (kernel_size[0] - 1) - 1) / stride[0] + 1).astype(int),\n",
    "                np.floor((img_size[1] + 2 * padding[1] - (kernel_size[1] - 1) - 1) / stride[1] + 1).astype(int))\n",
    "    return outshape\n",
    "\n",
    "def convtrans2D_output_size(img_size, padding, kernel_size, stride):\n",
    "    # compute output shape of conv2D\n",
    "    outshape = ((img_size[0] - 1) * stride[0] - 2 * padding[0] + kernel_size[0],\n",
    "                (img_size[1] - 1) * stride[1] - 2 * padding[1] + kernel_size[1])\n",
    "    return outshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1606702381621,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "ZIZN8ksj6H9d"
   },
   "outputs": [],
   "source": [
    "## ---------------------- ResNet VAE ---------------------- ##\n",
    "\n",
    "class ResNet_VAE(nn.Module):\n",
    "    def __init__(self, fc_hidden1=1024, fc_hidden2=768, drop_p=0.3, CNN_embed_dim=256):\n",
    "        super(ResNet_VAE, self).__init__()\n",
    "\n",
    "        self.fc_hidden1, self.fc_hidden2, self.CNN_embed_dim = fc_hidden1, fc_hidden2, CNN_embed_dim\n",
    "\n",
    "        # CNN architechtures\n",
    "        self.ch1, self.ch2, self.ch3, self.ch4 = 16, 32, 64, 128\n",
    "        self.k1, self.k2, self.k3, self.k4 = (5, 5), (3, 3), (3, 3), (3, 3)      # 2d kernal size\n",
    "        self.s1, self.s2, self.s3, self.s4 = (2, 2), (2, 2), (2, 2), (2, 2)      # 2d strides\n",
    "        self.pd1, self.pd2, self.pd3, self.pd4 = (0, 0), (0, 0), (0, 0), (0, 0)  # 2d padding\n",
    "\n",
    "        # encoding components\n",
    "        resnet = models.resnet152(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(resnet.fc.in_features, self.fc_hidden1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.fc_hidden1, momentum=0.01)\n",
    "        self.fc2 = nn.Linear(self.fc_hidden1, self.fc_hidden2)\n",
    "        self.bn2 = nn.BatchNorm1d(self.fc_hidden2, momentum=0.01)\n",
    "        # Latent vectors mu and sigma\n",
    "        self.fc3_mu = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)      # output = CNN embedding latent variables\n",
    "        self.fc3_logvar = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)  # output = CNN embedding latent variables\n",
    "\n",
    "        # Sampling vector\n",
    "        self.fc4 = nn.Linear(self.CNN_embed_dim, self.fc_hidden2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(self.fc_hidden2)\n",
    "        self.fc5 = nn.Linear(self.fc_hidden2, 64 * 4 * 4)\n",
    "        self.fc_bn5 = nn.BatchNorm1d(64 * 4 * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Decoder\n",
    "        self.convTrans6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=self.k4, stride=self.s4,\n",
    "                               padding=self.pd4),\n",
    "            nn.BatchNorm2d(32, momentum=0.01),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.convTrans7 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=8, kernel_size=self.k3, stride=self.s3,\n",
    "                               padding=self.pd3),\n",
    "            nn.BatchNorm2d(8, momentum=0.01),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.convTrans8 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=3, kernel_size=self.k2, stride=self.s2,\n",
    "                               padding=self.pd2),\n",
    "            nn.BatchNorm2d(3, momentum=0.01),\n",
    "            nn.Sigmoid()    # y = (y1, y2, y3) \\in [0 ,1]^3\n",
    "        )\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.resnet(x)  # ResNet\n",
    "        x = x.view(x.size(0), -1)  # flatten output of conv\n",
    "\n",
    "        # FC layers\n",
    "        x = self.bn1(self.fc1(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(self.fc2(x))\n",
    "        x = self.relu(x)\n",
    "        # x = F.dropout(x, p=self.drop_p, training=self.training)\n",
    "        mu, logvar = self.fc3_mu(x), self.fc3_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.relu(self.fc_bn4(self.fc4(z)))\n",
    "        x = self.relu(self.fc_bn5(self.fc5(x))).view(-1, 64, 4, 4)\n",
    "        x = self.convTrans6(x)\n",
    "        x = self.convTrans7(x)\n",
    "        x = self.convTrans8(x)\n",
    "        x = F.interpolate(x, size=(224, 224), mode='bilinear')\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_reconst = self.decode(z)\n",
    "\n",
    "        return x_reconst, z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1606702382891,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "CTU7gjhV6HDA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1606702383992,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "5bARX3O25vHL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1606702385205,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "rtAU7A1_5vHM"
   },
   "outputs": [],
   "source": [
    "# EncoderCNN architecture\n",
    "CNN_fc_hidden1, CNN_fc_hidden2 = 1024, 1024\n",
    "CNN_embed_dim = 256     # latent dim extracted by 2D CNN\n",
    "res_size = 224        # ResNet image size\n",
    "dropout_p = 0.2       # dropout probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1606702386312,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "lfB_-dsk5vHM"
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "epochs = 50        # training epochs\n",
    "batch_size = 50\n",
    "learning_rate = 1e-3\n",
    "log_interval = 10   # interval for displaying training info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1606702387462,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "P1W3TXBZ5vHM"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "save_model_path = './results_Olivetti_face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1606702388883,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "0W33FK6K5vHM"
   },
   "outputs": [],
   "source": [
    "def check_mkdir(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    MSE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1606702389888,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "VqBXOQsk5vHM"
   },
   "outputs": [],
   "source": [
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    # set model as training mode\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    all_X, all_y, all_z, all_mu, all_logvar = [], [], [], [], []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        X, y = X.to(device), y.to(device).view(-1, )\n",
    "        N_count += X.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        X_reconst, z, mu, logvar = model(X)  # VAE\n",
    "        loss = loss_function(X_reconst, X, mu, logvar)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_X.extend(X.data.cpu().numpy())\n",
    "        all_y.extend(y.data.cpu().numpy())\n",
    "        all_z.extend(z.data.cpu().numpy())\n",
    "        all_mu.extend(mu.data.cpu().numpy())\n",
    "        all_logvar.extend(logvar.data.cpu().numpy())\n",
    "\n",
    "        # show information\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "    \n",
    "    all_X = np.stack(all_X, axis=0)\n",
    "    all_y = np.stack(all_y, axis=0)\n",
    "    all_z = np.stack(all_z, axis=0)\n",
    "    all_mu = np.stack(all_mu, axis=0)\n",
    "    all_logvar = np.stack(all_logvar, axis=0)\n",
    "\n",
    "    # save Pytorch models of best record\n",
    "    torch.save(model.state_dict(), os.path.join(save_model_path, 'model_epoch{}.pth'.format(epoch + 1)))  # save motion_encoder\n",
    "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
    "    print(\"Epoch {} model saved!\".format(epoch + 1))\n",
    "\n",
    "    return all_X, all_y, all_z, all_mu, all_logvar, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1606702391058,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "FDnzthBK5vHM"
   },
   "outputs": [],
   "source": [
    "def validation(model, device, optimizer, test_loader):\n",
    "    # set model as testing mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    all_X, all_y, all_z, all_mu, all_logvar = [], [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            X, y = X.to(device), y.to(device).view(-1, )\n",
    "            X_reconst, z, mu, logvar = model(X)\n",
    "\n",
    "            loss = loss_function(X_reconst, X, mu, logvar)\n",
    "            test_loss += loss.item()  # sum up batch loss\n",
    "\n",
    "            all_X.extend(X.data.cpu().numpy())\n",
    "            all_y.extend(y.data.cpu().numpy())\n",
    "            all_z.extend(z.data.cpu().numpy())\n",
    "            all_mu.extend(mu.data.cpu().numpy())\n",
    "            all_logvar.extend(logvar.data.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    all_X = np.stack(all_X, axis=0)\n",
    "    all_y = np.stack(all_y, axis=0)\n",
    "    all_z = np.stack(all_z, axis=0)\n",
    "    all_mu = np.stack(all_mu, axis=0)\n",
    "    all_logvar = np.stack(all_logvar, axis=0)\n",
    "\n",
    "    # show information\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}\\n'.format(len(test_loader.dataset), test_loss))\n",
    "    return all_X, all_y, all_z, all_mu, all_logvar, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1606702392106,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "g1ZsBhNR5vHN"
   },
   "outputs": [],
   "source": [
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1606702393306,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "4hCVdmGr5vHN"
   },
   "outputs": [],
   "source": [
    "# Data loading parameters\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 0, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4729,
     "status": "ok",
     "timestamp": 1606702398404,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "JfGn24WV5vHN",
    "outputId": "be041100-f4ef-42a7-936d-1cb6c123e1ec"
   },
   "outputs": [],
   "source": [
    "# Load the faces datasets\n",
    "data = fetch_olivetti_faces()\n",
    "face_img = data.images.reshape((data.images.shape[0], data.images.shape[1], data.images.shape[2]))\n",
    "face_img_resized = [np.tile(np.expand_dims(resize(face_img[i, :, :], (res_size, res_size), anti_aliasing=True), axis=0), (3, 1, 1)) for i in range(face_img.shape[0])]\n",
    "face_img_resized = np.stack(face_img_resized, axis=0)\n",
    "face_img_resized = torch.from_numpy(face_img_resized).float()\n",
    "labels = torch.from_numpy(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1606702399958,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "gX0rAh4V5vHN",
    "outputId": "ac2d4e18-957d-4fcd-864e-7cb8388dfa28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_img_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1606702401437,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "O2yGswsx5vHO"
   },
   "outputs": [],
   "source": [
    "olivetti_data = TensorDataset(face_img_resized, labels)\n",
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=olivetti_data, drop_last=True, **params)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=olivetti_data, drop_last=True, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "referenced_widgets": [
      "63a5ef4c7d5548e78bb0073998c352df",
      "fb63e3927ebe4551972681a0dbaa0fbb",
      "ce0104b6eef1448a866dcf3ceb6b3b5a",
      "39316e94e2204812a52386ee67847fb1",
      "f20c8c7fd95a4927ae218e47ae46d829",
      "16082d6026674859a7d512abad647e3f",
      "25eaa73944ca4801b91fbc6343a2633e",
      "973060832fd6403d85e15d3ae60a90da"
     ]
    },
    "executionInfo": {
     "elapsed": 11288,
     "status": "ok",
     "timestamp": 1606702432012,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "ALhkawYD5vHO",
    "outputId": "ea99f7ff-12f5-4560-cba8-a962d27f186c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 GPU!\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "resnet_vae = ResNet_VAE(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim).to(device)\n",
    "\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPU!\")\n",
    "model_params = list(resnet_vae.parameters())\n",
    "optimizer = torch.optim.Adam(model_params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1421243,
     "status": "error",
     "timestamp": 1606703878158,
     "user": {
      "displayName": "‍김민회(학부학생/상경대학 응용통계학과)",
      "photoUrl": "",
      "userId": "16569322037062107098"
     },
     "user_tz": -540
    },
    "id": "pU5L8jpR5vHO",
    "outputId": "e9c33763-e578-49a7-a05f-83588f7447f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10/400 (2%)]\tLoss: 21380899102785536.000000\n",
      "Train Epoch: 1 [20/400 (5%)]\tLoss: 104394.023438\n",
      "Train Epoch: 1 [30/400 (8%)]\tLoss: 103751.164062\n",
      "Train Epoch: 1 [40/400 (10%)]\tLoss: 103016.046875\n",
      "Train Epoch: 1 [50/400 (12%)]\tLoss: 99580.437500\n",
      "Train Epoch: 1 [60/400 (15%)]\tLoss: 90745.710938\n",
      "Train Epoch: 1 [70/400 (18%)]\tLoss: 110095.179688\n",
      "Train Epoch: 1 [80/400 (20%)]\tLoss: 100254.703125\n",
      "Train Epoch: 1 [90/400 (22%)]\tLoss: 100482.929688\n",
      "Train Epoch: 1 [100/400 (25%)]\tLoss: 96275.617188\n",
      "Train Epoch: 1 [110/400 (28%)]\tLoss: 98186.351562\n",
      "Train Epoch: 1 [120/400 (30%)]\tLoss: 98413.421875\n",
      "Train Epoch: 1 [130/400 (32%)]\tLoss: 101080.195312\n",
      "Train Epoch: 1 [140/400 (35%)]\tLoss: 98944.000000\n",
      "Train Epoch: 1 [150/400 (38%)]\tLoss: 101306.453125\n",
      "Train Epoch: 1 [160/400 (40%)]\tLoss: 99560.843750\n",
      "Train Epoch: 1 [170/400 (42%)]\tLoss: 103118.468750\n",
      "Train Epoch: 1 [180/400 (45%)]\tLoss: 94832.312500\n",
      "Train Epoch: 1 [190/400 (48%)]\tLoss: 100474.398438\n",
      "Train Epoch: 1 [200/400 (50%)]\tLoss: 103819.085938\n",
      "Train Epoch: 1 [210/400 (52%)]\tLoss: 102408.453125\n",
      "Train Epoch: 1 [220/400 (55%)]\tLoss: 100939.843750\n",
      "Train Epoch: 1 [230/400 (58%)]\tLoss: 101222.609375\n",
      "Train Epoch: 1 [240/400 (60%)]\tLoss: 103671.500000\n",
      "Train Epoch: 1 [250/400 (62%)]\tLoss: 100166.250000\n",
      "Train Epoch: 1 [260/400 (65%)]\tLoss: 100413.914062\n",
      "Train Epoch: 1 [270/400 (68%)]\tLoss: 99747.554688\n",
      "Train Epoch: 1 [280/400 (70%)]\tLoss: 102840.328125\n",
      "Train Epoch: 1 [290/400 (72%)]\tLoss: 103778.281250\n",
      "Train Epoch: 1 [300/400 (75%)]\tLoss: 102193.687500\n",
      "Train Epoch: 1 [310/400 (78%)]\tLoss: 103927.101562\n",
      "Train Epoch: 1 [320/400 (80%)]\tLoss: 100466.164062\n",
      "Train Epoch: 1 [330/400 (82%)]\tLoss: 104146.656250\n",
      "Train Epoch: 1 [340/400 (85%)]\tLoss: 103188.882812\n",
      "Train Epoch: 1 [350/400 (88%)]\tLoss: 102834.921875\n",
      "Train Epoch: 1 [360/400 (90%)]\tLoss: 101821.687500\n",
      "Train Epoch: 1 [370/400 (92%)]\tLoss: 102171.062500\n",
      "Train Epoch: 1 [380/400 (95%)]\tLoss: 100454.437500\n",
      "Train Epoch: 1 [390/400 (98%)]\tLoss: 103701.859375\n",
      "Train Epoch: 1 [400/400 (100%)]\tLoss: 101696.945312\n",
      "Epoch 1 model saved!\n",
      "\n",
      "Test set (400 samples): Average loss: 102051.1278\n",
      "\n",
      "Train Epoch: 2 [10/400 (2%)]\tLoss: 98912.656250\n",
      "Train Epoch: 2 [20/400 (5%)]\tLoss: 101993.742188\n",
      "Train Epoch: 2 [30/400 (8%)]\tLoss: 97552.679688\n",
      "Train Epoch: 2 [40/400 (10%)]\tLoss: 100963.328125\n",
      "Train Epoch: 2 [50/400 (12%)]\tLoss: 101424.570312\n",
      "Train Epoch: 2 [60/400 (15%)]\tLoss: 99117.296875\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ec1a13eba647>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# train, test model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet_vae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_test_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnet_vae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-7893bfc9507a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(log_interval, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mX_reconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# VAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_reconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-692f0afb451d>\u001b[0m in \u001b[0;36mloss_function\u001b[1;34m(recon_x, x, mu, logvar)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# MSE = F.mse_loss(recon_x, x, reduction='sum')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mKLD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mMSE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mKLD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2483\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[1;32m-> 2484\u001b[1;33m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[0;32m   2485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "# record training process\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "check_mkdir(save_model_path)\n",
    "\n",
    "# start training\n",
    "for epoch in range(epochs):\n",
    "    # train, test model\n",
    "    X_train, y_train, z_train, mu_train, logvar_train, train_losses = train(log_interval, resnet_vae, device, train_loader, optimizer, epoch)\n",
    "    X_test, y_test, z_test, mu_test, logvar_test, epoch_test_loss = validation(resnet_vae, device, optimizer, valid_loader)\n",
    "\n",
    "    # save results\n",
    "    epoch_train_losses.append(train_losses)\n",
    "    epoch_test_losses.append(epoch_test_loss)\n",
    "\n",
    "    # save all train test results\n",
    "    A = np.array(epoch_train_losses)\n",
    "    C = np.array(epoch_test_losses)\n",
    "    \n",
    "    np.save(os.path.join(save_model_path, 'ResNet_VAE_training_loss.npy'), A)\n",
    "    np.save(os.path.join(save_model_path, 'X_Olivetti_train_epoch{}.npy'.format(epoch + 1)), X_train)\n",
    "    np.save(os.path.join(save_model_path, 'y_Olivetti_train_epoch{}.npy'.format(epoch + 1)), y_train)\n",
    "    np.save(os.path.join(save_model_path, 'z_Olivetti_train_epoch{}.npy'.format(epoch + 1)), z_train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ResNet_Olivetti.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "16082d6026674859a7d512abad647e3f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25eaa73944ca4801b91fbc6343a2633e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39316e94e2204812a52386ee67847fb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_973060832fd6403d85e15d3ae60a90da",
      "placeholder": "​",
      "style": "IPY_MODEL_25eaa73944ca4801b91fbc6343a2633e",
      "value": " 230M/230M [02:25&lt;00:00, 1.66MB/s]"
     }
    },
    "63a5ef4c7d5548e78bb0073998c352df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce0104b6eef1448a866dcf3ceb6b3b5a",
       "IPY_MODEL_39316e94e2204812a52386ee67847fb1"
      ],
      "layout": "IPY_MODEL_fb63e3927ebe4551972681a0dbaa0fbb"
     }
    },
    "973060832fd6403d85e15d3ae60a90da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce0104b6eef1448a866dcf3ceb6b3b5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16082d6026674859a7d512abad647e3f",
      "max": 241530880,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f20c8c7fd95a4927ae218e47ae46d829",
      "value": 241530880
     }
    },
    "f20c8c7fd95a4927ae218e47ae46d829": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fb63e3927ebe4551972681a0dbaa0fbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
